<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Setup Instructions | Comprehensive Guide to Transformers for Computer Vision Engineers</title>
    <link rel="stylesheet" href="/Comprehensive-Guide-to-Transformers-for-CV/assets/css/style.css?v=ba104ec3b0ab519b06b569f7a0316fb73ba22b23">
    <!-- MathJax support for equations -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- Syntax highlighting -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>

<!-- Custom favicon -->
<link rel="icon" type="image/png" href="/Comprehensive-Guide-to-Transformers-for-CV/assets/images/favicon.svg">

<!-- Open Graph / Social Media Meta Tags -->
<meta property="og:title" content="Setup Instructions">
<meta property="og:description" content="A comprehensive guide covering transformer theory and applications in computer vision">
<meta property="og:url" content="https://trietvo3105.github.io/Comprehensive-Guide-to-Transformers-for-CV/setup-instructions.html">
<meta property="og:site_name" content="Comprehensive Guide to Transformers for Computer Vision Engineers">
<meta property="og:type" content="website"> 
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Setup Instructions | Comprehensive Guide to Transformers for Computer Vision Engineers</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Setup Instructions" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A comprehensive guide covering transformer theory and applications in computer vision" />
<meta property="og:description" content="A comprehensive guide covering transformer theory and applications in computer vision" />
<link rel="canonical" href="https://trietvo3105.github.io/Comprehensive-Guide-to-Transformers-for-CV/setup-instructions.html" />
<meta property="og:url" content="https://trietvo3105.github.io/Comprehensive-Guide-to-Transformers-for-CV/setup-instructions.html" />
<meta property="og:site_name" content="Comprehensive Guide to Transformers for Computer Vision Engineers" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Setup Instructions" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"A comprehensive guide covering transformer theory and applications in computer vision","headline":"Setup Instructions","url":"https://trietvo3105.github.io/Comprehensive-Guide-to-Transformers-for-CV/setup-instructions.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      <header>
        <h1><a href="https://trietvo3105.github.io/Comprehensive-Guide-to-Transformers-for-CV/">Comprehensive Guide to Transformers for Computer Vision Engineers</a></h1>
        <nav class="main-nav">
          <a href="/Comprehensive-Guide-to-Transformers-for-CV/">Home</a>
          <a href="/Comprehensive-Guide-to-Transformers-for-CV/comprehensive">Overview</a>
          <a href="/Comprehensive-Guide-to-Transformers-for-CV/transformer-theory">Theory</a>
          <a href="/Comprehensive-Guide-to-Transformers-for-CV/transformer-applications">Applications</a>
          <a href="/Comprehensive-Guide-to-Transformers-for-CV/setup-instructions">Setup</a>
          <a href="/Comprehensive-Guide-to-Transformers-for-CV/hands-on-practice">Practice</a>
          <a href="/Comprehensive-Guide-to-Transformers-for-CV/styling-demo">Demo</a>
        </nav>
      </header>
      <main>
        <h1 id="setup-instructions-for-vision-transformer-hands-on-practice">Setup Instructions for Vision Transformer Hands-on Practice</h1>

<p>This guide provides detailed instructions for setting up your environment to work with Vision Transformers. Whether you’re using a local machine with or without a GPU, or a cloud-based solution like Google Colab, these instructions will help you get started quickly.</p>

<h2 id="environment-options">Environment Options</h2>

<p>You have several options for setting up your environment:</p>

<ol>
  <li><strong>Google Colab (Recommended for beginners)</strong>: Free access to GPUs with minimal setup</li>
  <li><strong>Local setup with GPU</strong>: Fastest performance but requires compatible hardware</li>
  <li><strong>Local setup without GPU</strong>: Limited to smaller models but works on any computer</li>
  <li><strong>Cloud-based alternatives</strong>: Options like Kaggle Notebooks or AWS SageMaker</li>
</ol>

<h2 id="option-1-google-colab-setup">Option 1: Google Colab Setup</h2>

<p>Google Colab provides free access to GPUs and comes with many pre-installed libraries, making it ideal for beginners.</p>

<h3 id="step-1-access-google-colab">Step 1: Access Google Colab</h3>

<ol>
  <li>Go to <a href="https://colab.research.google.com/">Google Colab</a></li>
  <li>Sign in with your Google account</li>
</ol>

<h3 id="step-2-create-a-new-notebook">Step 2: Create a New Notebook</h3>

<ol>
  <li>Click on <code class="language-plaintext highlighter-rouge">File &gt; New Notebook</code></li>
  <li>Rename the notebook by clicking on “Untitled0” at the top</li>
</ol>

<h3 id="step-3-configure-gpu-runtime">Step 3: Configure GPU Runtime</h3>

<figure>
  <img src="https://miro.medium.com/v2/resize:fit:1400/1*Lad06lrjlU9UZgSTHUHLJA.png" alt="Google Colab GPU Setup" />
  <figcaption>Figure 1: Selecting GPU runtime in Google Colab</figcaption>
</figure>

<ol>
  <li>Click on <code class="language-plaintext highlighter-rouge">Runtime &gt; Change runtime type</code></li>
  <li>Select <code class="language-plaintext highlighter-rouge">GPU</code> from the Hardware accelerator dropdown</li>
  <li>Click <code class="language-plaintext highlighter-rouge">Save</code></li>
</ol>

<p>Free Colab sessions have limitations:</p>

<ul>
  <li>Sessions timeout after 12 hours of inactivity</li>
  <li>Limited GPU usage per day</li>
  <li>Shared resources may affect performance</li>
</ul>

<h3 id="step-4-install-required-libraries">Step 4: Install Required Libraries</h3>

<p>Run the following code in a cell to install the necessary libraries:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span> <span class="n">tqdm</span> <span class="n">matplotlib</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">timm</span>  <span class="c1"># For Vision Transformer implementations
</span></code></pre></div></div>

<h3 id="step-5-verify-gpu-access">Step 5: Verify GPU Access</h3>

<p>Run this code to confirm that PyTorch can access the GPU:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">__version__</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"CUDA available: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"CUDA device: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="option-2-local-setup-with-gpu">Option 2: Local Setup with GPU</h2>

<p>If you have a compatible NVIDIA GPU, setting up a local environment will provide the best performance.</p>

<h3 id="step-1-install-cuda-and-cudnn">Step 1: Install CUDA and cuDNN</h3>

<ol>
  <li>Check your GPU compatibility at <a href="https://developer.nvidia.com/cuda-gpus">NVIDIA’s CUDA GPUs list</a></li>
  <li>Download and install the appropriate CUDA version from <a href="https://developer.nvidia.com/cuda-downloads">NVIDIA’s CUDA download page</a></li>
  <li>Download and install cuDNN from <a href="https://developer.nvidia.com/cudnn">NVIDIA’s cuDNN page</a> (requires free NVIDIA developer account)</li>
</ol>

<h3 id="step-2-create-a-conda-environment">Step 2: Create a Conda Environment</h3>

<ol>
  <li>Install <a href="https://www.anaconda.com/products/individual">Anaconda</a> or <a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a></li>
  <li>Open a terminal or Anaconda prompt</li>
  <li>Create a new environment:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create <span class="nt">-n</span> vit <span class="nv">python</span><span class="o">=</span>3.8
conda activate vit
</code></pre></div></div>

<h3 id="step-3-install-pytorch-with-gpu-support">Step 3: Install PyTorch with GPU Support</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda <span class="nb">install </span>pytorch torchvision torchaudio <span class="nv">cudatoolkit</span><span class="o">=</span>11.3 <span class="nt">-c</span> pytorch
</code></pre></div></div>

<p>Replace <code class="language-plaintext highlighter-rouge">cudatoolkit=11.3</code> with the version that matches your installed CUDA version. Check compatibility at <a href="https://pytorch.org/get-started/locally/">PyTorch’s installation page</a>.</p>

<h3 id="step-4-install-additional-libraries">Step 4: Install Additional Libraries</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>timm matplotlib tqdm jupyter
</code></pre></div></div>

<h3 id="step-5-verify-gpu-access-1">Step 5: Verify GPU Access</h3>

<p>Launch Python and run:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">__version__</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"CUDA available: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"CUDA device: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>If you’re having issues with GPU detection, try the following:</p>

<ol>
  <li>Ensure your GPU drivers are up to date</li>
  <li>Check that CUDA and PyTorch versions are compatible</li>
  <li>Try reinstalling PyTorch with the specific CUDA version you have installed</li>
</ol>

<h2 id="option-3-local-setup-without-gpu">Option 3: Local Setup without GPU</h2>

<p>If you don’t have a compatible GPU, you can still run smaller models on your CPU.</p>

<h3 id="step-1-create-a-conda-environment">Step 1: Create a Conda Environment</h3>

<ol>
  <li>Install <a href="https://www.anaconda.com/products/individual">Anaconda</a> or <a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a></li>
  <li>Open a terminal or Anaconda prompt</li>
  <li>Create a new environment:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create <span class="nt">-n</span> vit <span class="nv">python</span><span class="o">=</span>3.8
conda activate vit
</code></pre></div></div>

<h3 id="step-2-install-pytorch-cpu-version">Step 2: Install PyTorch (CPU Version)</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda <span class="nb">install </span>pytorch torchvision torchaudio cpuonly <span class="nt">-c</span> pytorch
</code></pre></div></div>

<h3 id="step-3-install-additional-libraries">Step 3: Install Additional Libraries</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>timm matplotlib tqdm jupyter
</code></pre></div></div>

<p>Running Vision Transformers on CPU will be significantly slower than on GPU. Consider:</p>

<ul>
  <li>Using smaller models with fewer parameters</li>
  <li>Reducing batch sizes</li>
  <li>Processing fewer images</li>
  <li>Using pre-computed features when possible</li>
</ul>

<h2 id="option-4-cloud-based-alternatives">Option 4: Cloud-based Alternatives</h2>

<p>If Google Colab doesn’t meet your needs, consider these alternatives:</p>

<h3 id="kaggle-notebooks">Kaggle Notebooks</h3>

<ol>
  <li>Create an account at <a href="https://www.kaggle.com/">Kaggle</a></li>
  <li>Go to “Notebooks” and click “New Notebook”</li>
  <li>Under “Settings”, select GPU accelerator</li>
  <li>Libraries like PyTorch, torchvision, and timm are pre-installed</li>
</ol>

<h3 id="aws-sagemaker">AWS SageMaker</h3>

<p>For more advanced users or those needing longer runtimes:</p>

<ol>
  <li>Create an <a href="https://aws.amazon.com/">AWS account</a></li>
  <li>Navigate to SageMaker in the AWS console</li>
  <li>Create a notebook instance with GPU support (e.g., ml.p3.2xlarge)</li>
  <li>Choose a PyTorch or conda kernel</li>
</ol>

<h2 id="downloading-datasets">Downloading Datasets</h2>

<p>For the hands-on exercises, we’ll use several datasets. Here’s how to download them:</p>

<p>The main datasets we’ll be using include:</p>

<ol>
  <li><strong>CIFAR-10</strong>: A dataset of 60,000 32x32 color images in 10 classes</li>
  <li><strong>Flowers-102</strong>: A dataset of 102 flower categories</li>
  <li><strong>ImageNet</strong>: A subset for inference with pre-trained models</li>
</ol>

<p>These datasets are automatically downloaded by the code in our exercises, but you can also pre-download them if you prefer.</p>

<h3 id="cifar-10">CIFAR-10</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="c1"># This will download CIFAR-10 to ./data/cifar-10
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="imagenet-subset">ImageNet (Subset)</h3>

<p>For exercises requiring ImageNet, we’ll use a subset called ImageNette:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="p">.</span><span class="n">amazonaws</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">fast</span><span class="o">-</span><span class="n">ai</span><span class="o">-</span><span class="n">imageclas</span><span class="o">/</span><span class="n">imagenette2</span><span class="o">-</span><span class="mf">320.</span><span class="n">tgz</span>
<span class="err">!</span><span class="n">tar</span> <span class="o">-</span><span class="n">xzf</span> <span class="n">imagenette2</span><span class="o">-</span><span class="mf">320.</span><span class="n">tgz</span>
</code></pre></div></div>

<h2 id="testing-your-environment">Testing Your Environment</h2>

<p>To ensure everything is set up correctly, run this simple test:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">timm</span>

<span class="c1"># Check PyTorch and GPU
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">__version__</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"CUDA available: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"CUDA device: </span><span class="si">{</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Test loading a ViT model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="p">.</span><span class="n">create_model</span><span class="p">(</span><span class="s">'vit_base_patch16_224'</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model loaded successfully: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Test moving model to appropriate device
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model moved to: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()).</span><span class="n">device</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>If you see the model name printed and no errors, congratulations! Your environment is set up correctly and you’re ready to start working with Vision Transformers.</p>

<h2 id="troubleshooting-common-issues">Troubleshooting Common Issues</h2>

<h3 id="cuda-out-of-memory">CUDA Out of Memory</h3>

<ul>
  <li>Reduce batch size</li>
  <li>Use a smaller model variant</li>
  <li>Try gradient accumulation</li>
</ul>

<h3 id="package-conflicts">Package Conflicts</h3>

<ul>
  <li>Create a fresh conda environment</li>
  <li>Install packages in the recommended order</li>
  <li>Check version compatibility between PyTorch and CUDA</li>
</ul>

<h3 id="import-errors">Import Errors</h3>

<ul>
  <li>Ensure you’ve activated the correct environment</li>
  <li>Reinstall problematic packages</li>
  <li>Check for missing dependencies</li>
</ul>

<h3 id="slow-performance-on-gpu">Slow Performance on GPU</h3>

<ul>
  <li>Check if PyTorch is actually using the GPU (<code class="language-plaintext highlighter-rouge">next(model.parameters()).device</code>)</li>
  <li>Update GPU drivers</li>
  <li>Close other GPU-intensive applications</li>
</ul>

<h2 id="next-steps">Next Steps</h2>

<p>Now that your environment is set up, you’re ready to start working with Vision Transformers! Proceed to the Hands-on Practice section to begin implementing and experimenting with these powerful models.</p>

<p>In the hands-on practice, you’ll learn how to:</p>

<ul>
  <li>Load and preprocess image data</li>
  <li>Implement a basic Vision Transformer from scratch</li>
  <li>Fine-tune pre-trained ViT models</li>
  <li>Visualize attention maps</li>
  <li>Apply ViT to various computer vision tasks</li>
</ul>


      </main>
      <footer>
        <p>&copy; 2025. All rights reserved.</p>
      </footer>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html> 